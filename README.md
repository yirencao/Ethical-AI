# AI Ethics in Large Language Models

## Description
This repository contains the resources and notebooks for our project focused on integrating ethical considerations into AI systems, particularly Large Language Models (LLMs) like LLaMA. Our aim is to explore how AI systems can handle ethical dilemmas and align more closely with human ethical values, using a combination of technical and philosophical approaches.

## Contents
- `/data/`: Contains the [ETHICS](https://github.com/hendrycks/ethics) and the [Red-teaming (from Anthropics)](https://github.com/anthropics/ConstitutionalHarmlessnessPaper/tree/main/evals) datasets. 
- `/1. preprocessing/`: Contains notebooks for preparing and structuring the datasets for model training and evaluation.
- `/2. modelling/Model_Tuning.ipynb`: Details the process of fine-tuning the LLaMA model using QLoRA for efficient resource utilization.
- `/3. evaluation/Data_Evaluation.py`: Demonstrates how to process and evaluate the outputs from the model.
- `/4. results/`: Contains the results generated by the model, as well as comprehensive analysis of the model's performance pre and post fine-tuning.

## Project Structure
- Week-by-week plan documenting our progress.
- Milestones marking key stages in our research and development process.
- Comprehensive notes on ethical theories and AI model training considerations.

## Installation and Usage
- Clone the repository: `git clone [repository link]`
- Install required packages: `pip install -r requirements.txt`
- Follow the notebooks in order for a step-by-step guide through the project.

## Dataset
The ETHICS dataset, encompassing scenarios representing justice, virtue, deontology, utilitarianism, and common-sense morality, forms the core of our model training and evaluation.

## Model
Utilizing LLaMA 2 as our baseline, enhanced by QLoRA for fine-tuning, we aim to balance high performance with alignment to human ethical values.
